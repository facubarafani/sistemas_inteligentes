{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas Inteligentes: Trabajo práctico 3\n",
    "\n",
    "## Integrantes\n",
    "\n",
    "* **BARAFANI**, Facundo\n",
    "* ***ROJAS**, Juan Pablo\n",
    "\n",
    "## Consigna\n",
    "\n",
    "Entrenar algunas de las redes anteriores para otro conjunto de datos.\n",
    "\n",
    "Optamos por entrenar una RNN usando YOLO, para la detección de barbijo en el rostro haciendo uso del siguiente dataset: https://www.kaggle.com/datasets/andrewmvd/face-mask-detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias\n",
    "\n",
    "Comenzamos importando librerias que nos van a ser de utilidad para poder importar, manipular algunos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importa la librería pandas para el manejo de datos tabulares\n",
    "import numpy as np  # Importa la librería numpy para operaciones matemáticas en arrays multidimensionales\n",
    "import matplotlib.pyplot as plt  # Importa la librería matplotlib para la visualización de gráficos\n",
    "import seaborn as sns  # Importa la librería seaborn para la mejora de la visualización de datos\n",
    "import os  # Importa la librería os para interactuar con el sistema operativo\n",
    "import cv2  # Importa la librería cv2 de OpenCV para el procesamiento de imágenes y videos\n",
    "import PIL  # Importa la librería PIL para manipular imágenes en Python\n",
    "import xml.etree.ElementTree as ET  # Importa el módulo ElementTree de la librería xml para trabajar con XML\n",
    "import glob  # Importa la librería glob para buscar archivos que coincidan con un patrón\n",
    "import time  # Importa la librería time para trabajar con operaciones relacionadas con el tiempo\n",
    "import datetime  # Importa la librería datetime para trabajar con fechas y horas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de imagenes\n",
    "\n",
    "Procedemos a cargar las imagenes del dataset, la cual contiene ejemplos de distintas personas utilizando el barbijo puesto, barbijo mal puesto y sin barbijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de imágenes\n",
    "img_dir = './kaggle/input/face-mask-detection/images'\n",
    "\n",
    "# Directorio donde se encuentran las etiquestas en formato XML\n",
    "annotation_dir = './kaggle/input/face-mask-detection/annotations'\n",
    "\n",
    "# Directorio de input del modelo\n",
    "input_dir = './kaggle/input/face-mask-detection'\n",
    "\n",
    "# Directorio de output del modelo\n",
    "output_dir = './kaggle/working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m current_directory \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(current_file_path)\n\u001b[1;32m      5\u001b[0m os\u001b[39m.\u001b[39mchdir(current_directory)\n\u001b[0;32m----> 7\u001b[0m os\u001b[39m.\u001b[39mlistdir(img_dir)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m idx, image \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(os\u001b[39m.\u001b[39mlistdir(img_dir)):\n\u001b[1;32m      9\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(img_dir, image), \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtenemos la ruta completa a el archivo actual\n",
    "current_file_path = os.path.realpath('__file__')\n",
    "\n",
    "# Obtenemos el directorio del archivo actual\n",
    "current_directory = os.path.dirname(current_file_path)\n",
    "\n",
    "# Cambiamos el directorio de trabajo al directorio actual\n",
    "os.chdir(current_directory)\n",
    "\n",
    "os.listdir(img_dir)\n",
    "for idx, image in enumerate(os.listdir(img_dir)):\n",
    "    img = cv2.imread(os.path.join(img_dir, image), 1)\n",
    "\n",
    "    # Mostramos las imagenes\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    # Salimos luego de 3 imagenes ya que solo es a modo de prueba\n",
    "    if idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n"
     ]
    }
   ],
   "source": [
    "img_file_path = []\n",
    "for img in os.listdir(img_dir):\n",
    "    # Leemos la imagen en escala de grises utilizando OpenCV\n",
    "    image  = cv2.imread(os.path.join(img_dir, img), 0)\n",
    "    img_file_path.append(f'{img}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validamos la cantidad de archivos que hay dentro del nuevo arreglo con las rutas a las imagenes.\n",
    "len(img_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maksssksksss299\n"
     ]
    }
   ],
   "source": [
    "# A modo de prueba verificamos que este codigo lo que nos permite es sacar la extensión del archivo ya que nos va a ser util en la proxima situación para\n",
    "# poder extraer los datos necesiarios de las etiquetas en formato .xml\n",
    "for i in glob.glob(annotation_dir+'/*.xml'):\n",
    "    print(i.split('/')[-1][0:-4])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de etiquetas (labels)\n",
    "\n",
    "Para la generación de las etiquetas, el dataset cuenta con archivos XML que almacenan información de la foto, como el alto y ancho de esta y a su vez las coordenadas que delimitan a la misma, es por esto que hicimos uso de librerias como **ElementTree** para poder leer el archivo .XML y asi poder sacar los valores que nos seran utiles para luego entrenar al modelo:\n",
    "\n",
    "**Variables a considerar**:\n",
    "\n",
    "1- **name:** Contiene el nombre de la etiqueta de la imagen, las opciones son: without_mask, with_mask, mask_weared_incorrect\n",
    "2- **width, height:** Ancho y alto de la foto.\n",
    "3- **xmin, ymin, xmax, ymax:** Coordenadas que delimitan la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar los datos de las etiquetas alojadas en el directorio 'annotations'\n",
    "df = { 'name': [],\n",
    "        'label': [],\n",
    "      'width': [],\n",
    "      'height': [],\n",
    "     'xmin': [],\n",
    "     'ymin': [],\n",
    "     'xmax': [],\n",
    "     'ymax': []}\n",
    "\n",
    "for idx, anno in enumerate(glob.glob(annotation_dir + '/*.xml')):\n",
    "    # Leemos el archivo xml\n",
    "    trees = ET.parse(anno)\n",
    "    root = trees.getroot()\n",
    "\n",
    "    # Instanciamos variables para almacener al ancho y alto de la foto\n",
    "    width, height = [], []\n",
    "\n",
    "    # Iteramos sobre los distintos elementos que tiene el archivo xml\n",
    "    for item in root.iter():               \n",
    "        if item.tag == 'size': # Accedemos a la etiqueta 'size' para sacar el alto y ancho de la foto\n",
    "            for attr in list(item):\n",
    "                if attr.tag == 'width':\n",
    "                    width = int(round(float(attr.text)))\n",
    "                if attr.tag == 'height':\n",
    "                    height = int(round(float(attr.text)))\n",
    "                    \n",
    "        if item.tag == 'object': # Accedemos a 'object' para obtener la etiqueta que se le va a asignar a la foto y las coordenadas que delimitan la foto\n",
    "            for attr in list(item):\n",
    "                if 'name' in attr.tag:\n",
    "                    label = attr.text\n",
    "                    df['label'] += [label]\n",
    "                    df['width'] += [width]\n",
    "                    df['height'] += [height]\n",
    "                    df['name'] += [anno.split('/')[-1][0:-4]] # Eliminamos los ultimos 4 caracteres para sacar la extension del archivo\n",
    "                    \n",
    "                if 'bndbox' in attr.tag:\n",
    "                    for dim in attr:\n",
    "                        if dim.tag == 'xmin':\n",
    "                            xmin = int(round(float(dim.text)))\n",
    "                            df['xmin'] += [xmin]\n",
    "                            \n",
    "                        if dim.tag == 'ymin':\n",
    "                            ymin = int(round(float(dim.text)))\n",
    "                            df['ymin'] += [ymin]\n",
    "                        if dim.tag == 'xmax':\n",
    "                            xmax = int(round(float(dim.text)))\n",
    "                            df['xmax'] += [xmax]\n",
    "                        if dim.tag == 'ymax':\n",
    "                            ymax = int(round(float(dim.text)))\n",
    "                            df['ymax'] += [ymax]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss299</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>62</td>\n",
       "      <td>194</td>\n",
       "      <td>160</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss528</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>43</td>\n",
       "      <td>169</td>\n",
       "      <td>149</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss272</td>\n",
       "      <td>mask_weared_incorrect</td>\n",
       "      <td>275</td>\n",
       "      <td>400</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>218</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>160</td>\n",
       "      <td>66</td>\n",
       "      <td>176</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label  width  height  xmin  ymin  xmax   \n",
       "0  maksssksksss299           without_mask    301     400    62   194   160  \\\n",
       "1  maksssksksss528           without_mask    301     400    43   169   149   \n",
       "2  maksssksksss272  mask_weared_incorrect    275     400    48   107   218   \n",
       "3  maksssksksss514              with_mask    400     267    28    78    43   \n",
       "4  maksssksksss514              with_mask    400     267   160    66   176   \n",
       "\n",
       "   ymax  \n",
       "0   320  \n",
       "1   308  \n",
       "2   304  \n",
       "3    99  \n",
       "4    83  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(df)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4072 entries, 0 to 4071\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   name    4072 non-null   object\n",
      " 1   label   4072 non-null   object\n",
      " 2   width   4072 non-null   int64 \n",
      " 3   height  4072 non-null   int64 \n",
      " 4   xmin    4072 non-null   int64 \n",
      " 5   ymin    4072 non-null   int64 \n",
      " 6   xmax    4072 non-null   int64 \n",
      " 7   ymax    4072 non-null   int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 254.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "with_mask                3232\n",
       "without_mask              717\n",
       "mask_weared_incorrect     123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = { 'without_mask': 0,\n",
    "            'with_mask': 1,\n",
    "            'mask_weared_incorrect': 2}\n",
    "\n",
    "df1['class'] = df1['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss299</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>62</td>\n",
       "      <td>194</td>\n",
       "      <td>160</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss528</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>43</td>\n",
       "      <td>169</td>\n",
       "      <td>149</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss272</td>\n",
       "      <td>mask_weared_incorrect</td>\n",
       "      <td>275</td>\n",
       "      <td>400</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>218</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>160</td>\n",
       "      <td>66</td>\n",
       "      <td>176</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label  width  height  xmin  ymin  xmax   \n",
       "0  maksssksksss299           without_mask    301     400    62   194   160  \\\n",
       "1  maksssksksss528           without_mask    301     400    43   169   149   \n",
       "2  maksssksksss272  mask_weared_incorrect    275     400    48   107   218   \n",
       "3  maksssksksss514              with_mask    400     267    28    78    43   \n",
       "4  maksssksksss514              with_mask    400     267   160    66   176   \n",
       "\n",
       "   ymax  class  \n",
       "0   320      0  \n",
       "1   308      0  \n",
       "2   304      2  \n",
       "3    99      1  \n",
       "4    83      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de la estructura para el entrenamiento del modelo YoloV5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del modelo en entrenamiento, prueba y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.25 * 4072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(img_file_path, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Length of train directory: 579\n",
      "==================================================\n",
      "Length of validation directory: 103\n",
      "==================================================\n",
      "Length of test directory: 171\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*50)\n",
    "print('Cantidad de imagenes de entrenamiento: {}'.format(len(train)))\n",
    "print('='*50)\n",
    "print('Cantidad de imagenes de validación: {}'.format(len(val)))\n",
    "print('='*50)\n",
    "print('Cantidad de imagenes de prueba: {}'.format(len(test)))\n",
    "print('='*50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de directorio para YoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)\n",
    "os.chdir('./kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 15978, done.\u001b[K\n",
      "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
      "remote: Total 15978 (delta 89), reused 110 (delta 70), pack-reused 15831\u001b[K\n",
      "Receiving objects: 100% (15978/15978), 14.54 MiB | 16.17 MiB/s, done.\n",
      "Resolving deltas: 100% (10963/10963), done.\n",
      "/Users/facundobarafani/Documents/UCC/sistemas_inteligentes/tp_final/kaggle/working/yolov5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/facundobarafani/Documents/UCC/sistemas_inteligentes/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: utils in /Users/facundobarafani/Documents/UCC/sistemas_inteligentes/venv/lib/python3.9/site-packages (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/facundobarafani/Documents/UCC/sistemas_inteligentes/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -qr requirements.txt\n",
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una carpeta separada para entrenamiento, validación y prueba\n",
    "os.chdir(current_directory)\n",
    "os.getcwd()\n",
    "os.chdir('./kaggle/working')\n",
    "os.mkdir('./yolov5/data/train')\n",
    "os.mkdir('./yolov5/data/val')\n",
    "os.mkdir('./yolov5/data/test')\n",
    "os.mkdir('./yolov5/data/train/images')\n",
    "os.mkdir('./yolov5/data/train/labels')\n",
    "os.mkdir('./yolov5/data/val/images')\n",
    "os.mkdir('./yolov5/data/val/labels')\n",
    "os.mkdir('./yolov5/data/test/images')\n",
    "os.mkdir('./yolov5/data/test/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el directorio de trabajo al directorio actual\n",
    "os.chdir(current_directory)\n",
    "os.getcwd()\n",
    "def copy_image_file(image_items, folder_name):\n",
    "    \n",
    "    for image in image_items:\n",
    "        img = PIL.Image.open(f'{img_dir}/{image}')\n",
    "        # Redimensionamos la foto a (640x480)\n",
    "        img1 = img.resize((640, 480))\n",
    "\n",
    "        # Guardamos la imagen\n",
    "        _ = img1.save(f'{output_dir}/yolov5/data/{folder_name}/images/{image}')\n",
    "\n",
    "# Invocamos la función para los distintos conjuntos\n",
    "copy_image_file(train, 'train')\n",
    "copy_image_file(val, 'val')\n",
    "copy_image_file(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss299</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>62</td>\n",
       "      <td>194</td>\n",
       "      <td>160</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss528</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>43</td>\n",
       "      <td>169</td>\n",
       "      <td>149</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss272</td>\n",
       "      <td>mask_weared_incorrect</td>\n",
       "      <td>275</td>\n",
       "      <td>400</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>218</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>160</td>\n",
       "      <td>66</td>\n",
       "      <td>176</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label  width  height  xmin  ymin  xmax   \n",
       "0  maksssksksss299           without_mask    301     400    62   194   160  \\\n",
       "1  maksssksksss528           without_mask    301     400    43   169   149   \n",
       "2  maksssksksss272  mask_weared_incorrect    275     400    48   107   218   \n",
       "3  maksssksksss514              with_mask    400     267    28    78    43   \n",
       "4  maksssksksss514              with_mask    400     267   160    66   176   \n",
       "\n",
       "   ymax  class  \n",
       "0   320      0  \n",
       "1   308      0  \n",
       "2   304      2  \n",
       "3    99      1  \n",
       "4    83      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiamos los labels en la carpeta que creamos para el yoloV5\n",
    "\n",
    "Ahora tenemos que cambiar la caja de la etiqueta, porque al cambiar el tamaño de la foto tenemos que cambiar el tamaño de la caja que va a tener la etiqueta, y a su vez encontrar el centro de las coordenadas\n",
    "\n",
    "**x = (new_x/older_x)* x**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss299</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>131.827243</td>\n",
       "      <td>232.800000</td>\n",
       "      <td>340.199336</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss528</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>91.428571</td>\n",
       "      <td>202.800000</td>\n",
       "      <td>316.810631</td>\n",
       "      <td>369.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss272</td>\n",
       "      <td>mask_weared_incorrect</td>\n",
       "      <td>275</td>\n",
       "      <td>400</td>\n",
       "      <td>111.709091</td>\n",
       "      <td>128.400000</td>\n",
       "      <td>507.345455</td>\n",
       "      <td>364.800000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>140.224719</td>\n",
       "      <td>68.800000</td>\n",
       "      <td>177.977528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>118.651685</td>\n",
       "      <td>281.600000</td>\n",
       "      <td>149.213483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label  width  height        xmin   \n",
       "0  maksssksksss299           without_mask    301     400  131.827243  \\\n",
       "1  maksssksksss528           without_mask    301     400   91.428571   \n",
       "2  maksssksksss272  mask_weared_incorrect    275     400  111.709091   \n",
       "3  maksssksksss514              with_mask    400     267   44.800000   \n",
       "4  maksssksksss514              with_mask    400     267  256.000000   \n",
       "\n",
       "         ymin        xmax        ymax  class  \n",
       "0  232.800000  340.199336  384.000000      0  \n",
       "1  202.800000  316.810631  369.600000      0  \n",
       "2  128.400000  507.345455  364.800000      2  \n",
       "3  140.224719   68.800000  177.977528      1  \n",
       "4  118.651685  281.600000  149.213483      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redimensionamos las coordenadas del 'bounding box'\n",
    "df1['xmin'] = (640/df1['width']) * df1['xmin']\n",
    "df1['ymin'] = (480/df1['height']) * df1['ymin']\n",
    "df1['xmax'] = (640/df1['width']) * df1['xmax']\n",
    "df1['ymax'] = (480/df1['height']) * df1['ymax']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casteamos las dimensiones a integer\n",
    "df1[['xmin', 'ymin', 'xmax', 'ymax']] = df1[['xmin', 'ymin', 'xmax', 'ymax']].astype('int')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el centro de x y de y, y tenemos en cuenta el punto medio del ancho y el alto de la boundix box.\n",
    "\n",
    "Siendo w el ancho y h el alto:\n",
    "\n",
    "**x = (x1+x2)(2w) --> y = (y1+y2)(2h) --> mid_w = (x2-x1)/(w) --> mid_h = (y2-y1)/(h)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 640\n",
    "HEIGHT = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el centro x del 'bounding box' normalizado\n",
    "df1['x_center'] = (df1['xmin']+df1['xmax'])/(2*WIDTH)\n",
    "\n",
    "# Calcular el centro y del 'bounding box' normalizado\n",
    "df1['y_center'] = (df1['ymin']+df1['ymax'])/(2*HEIGHT)\n",
    "\n",
    "# Calcular el ancho del 'bounding box' normalizado\n",
    "df1['box_width'] = (df1['xmax']-df1['xmin'])/ WIDTH\n",
    "\n",
    "# Calcular la altura del 'bounding box' normalizado\n",
    "df1['box_height'] = (df1['ymax']-df1['ymin'])/ HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss299</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>131</td>\n",
       "      <td>232</td>\n",
       "      <td>340</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367969</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.326562</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss528</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>301</td>\n",
       "      <td>400</td>\n",
       "      <td>91</td>\n",
       "      <td>202</td>\n",
       "      <td>316</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317969</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.347917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss272</td>\n",
       "      <td>mask_weared_incorrect</td>\n",
       "      <td>275</td>\n",
       "      <td>400</td>\n",
       "      <td>111</td>\n",
       "      <td>128</td>\n",
       "      <td>507</td>\n",
       "      <td>364</td>\n",
       "      <td>2</td>\n",
       "      <td>0.482812</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>0.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>44</td>\n",
       "      <td>140</td>\n",
       "      <td>68</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.330208</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.077083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss514</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>256</td>\n",
       "      <td>118</td>\n",
       "      <td>281</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419531</td>\n",
       "      <td>0.278125</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.064583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label  width  height  xmin  ymin  xmax   \n",
       "0  maksssksksss299           without_mask    301     400   131   232   340  \\\n",
       "1  maksssksksss528           without_mask    301     400    91   202   316   \n",
       "2  maksssksksss272  mask_weared_incorrect    275     400   111   128   507   \n",
       "3  maksssksksss514              with_mask    400     267    44   140    68   \n",
       "4  maksssksksss514              with_mask    400     267   256   118   281   \n",
       "\n",
       "   ymax  class  x_center  y_center  box_width  box_height  \n",
       "0   384      0  0.367969  0.641667   0.326562    0.316667  \n",
       "1   369      0  0.317969  0.594792   0.351562    0.347917  \n",
       "2   364      2  0.482812  0.512500   0.618750    0.491667  \n",
       "3   177      1  0.087500  0.330208   0.037500    0.077083  \n",
       "4   149      1  0.419531  0.278125   0.039062    0.064583  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       maksssksksss299\n",
       "1       maksssksksss528\n",
       "2       maksssksksss272\n",
       "3       maksssksksss514\n",
       "4       maksssksksss514\n",
       "             ...       \n",
       "4067    maksssksksss294\n",
       "4068    maksssksksss294\n",
       "4069    maksssksksss294\n",
       "4070    maksssksksss294\n",
       "4071    maksssksksss294\n",
       "Name: name, Length: 4072, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de las anotaciones para YOLOv5\n",
    "Generamos las etiquetas a partir del dataframe que creamos anteriormente que contiene la información sobre las 'bounding box' de los objetos de las imagenes. Las coordenadas redimensionadas y normalizadas se escriben en archivos .txt junto a su 'clase' correspondiente. Todo esto se hace para preparar los datos para ser entrenados para la detección de objetos usando YOLOv5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)\n",
    "os.getcwd()\n",
    "\n",
    "def copy_label(label_items, folder_name):\n",
    "    # Obtenemos el nombre del archivo sin extensión de cada imagen en img_file_path\n",
    "    file_name = [x.split('.')[0] for x in img_file_path]\n",
    "\n",
    "    # Iteramos sobre cada nombre de archivo\n",
    "    for name in file_name:\n",
    "        data = df1[df1.name == name]\n",
    "\n",
    "        box_list = []\n",
    "        for idx in range(len(data)):\n",
    "            row = data.iloc[idx]\n",
    "            box_list.append(row['class']+\" \"+row['x_center']+\" \"+row['y_center']+\" \"+ row['box_width']+\" \"+row['box_height'])\n",
    "\n",
    "        text = \"\\n\".join(box_list)\n",
    "\n",
    "        # Escribimos las etiquetas en un archivo de texto\n",
    "        with open(f'{output_dir}/yolov5/data/{folder_name}/labels/{name}.txt', 'w') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_label(train, 'train')\n",
    "copy_label(val, 'val')\n",
    "copy_label(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)\n",
    "os.getcwd()\n",
    "\n",
    "os.chdir('./kaggle/working/yolov5/data/train/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1828125 0.33645833333333336 0.059375 0.10208333333333333\n",
      "1 0.40078125 0.33229166666666665 0.0796875 0.11875\n",
      "0 0.66875 0.3145833333333333 0.06875 0.1375"
     ]
    }
   ],
   "source": [
    "cat maksssksksss0.txt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de YoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[39m.\u001b[39mchdir(current_directory)\n\u001b[1;32m      3\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m'\u001b[39m\u001b[39m./kaggle/working/yolov5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(current_directory)\n",
    "\n",
    "os.chdir('./kaggle/working/yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, clear_output\n",
    "import torch \n",
    "import tensorflow\n",
    "from yolov5 import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2023-6-11 Python-3.9.6 torch-2.0.1 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (10 CPUs, 16.0 GB RAM, 162.6/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos YOLOv5\n",
    "display = utils.notebook_init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configura el contenido de un archivo YAML que se utilizará para especificar la configuración de los datos de entrenamiento del modelo de detección de barbijos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el archivo .yaml\n",
    "yaml_file = \"\"\"train: data/train/images\n",
    "val: data/val/images\n",
    "                \n",
    "nc: 3\n",
    "names: [without_mask, with_mask, mask_weared_incorrect]\"\"\"\n",
    "\n",
    "with open('data/data.yaml', 'w') as f:\n",
    "    f.write(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: data/train/images\n",
      "val: data/val/images\n",
      "                \n",
      "nc: 3\n",
      "names: [without_mask, with_mask, mask_weared_incorrect]"
     ]
    }
   ],
   "source": [
    "%cat data/data.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función mágica personalizada en IPython llamada 'writetemplate' que nos permite escribir un archivo de texto utilizando un template y los valores de las variables globales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invocamos a la función mágica definida previamente\n",
    "%%writetemplate models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: 3  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "    - [10,13, 16,30, 33,23]  # P3/8\n",
    "    - [30,61, 62,45, 59,119]  # P4/16\n",
    "    - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "    [[-1, 1, Conv, [512, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "    [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "    [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "    [-1, 1, Conv, [256, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "    [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "    [-1, 1, Conv, [256, 3, 2]],\n",
    "    [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "    [-1, 1, Conv, [512, 3, 2]],\n",
    "    [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo YoloV5 usando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/custom_yolov5s.yaml, data=data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-178-ga199480 Python-3.9.6 torch-2.0.1 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_YOLOv5s summary: 233 layers, 7260488 parameters, 7260488 gradients\n",
      "\n",
      "Transferred 223/369 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 70 weight(decay=0.0005), 62 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/facundobarafani/Documents/UCC/sistemas_inteligentes/tp_fi\u001b[0m\n",
      "  0%|          | 0/579 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.5GB ram): 100%|██████████| 579/579 [00:00<00:00, 992.27\u001b[0m\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/facundobarafani/Documents/UCC/sistemas_inteligentes/tp_fina\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 103/103 [00:00<00:00, 380.07it\u001b[0m\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "WARNING  user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.65 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/yolov5s_results2/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov5s_results2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/99         0G     0.1068     0.0621    0.03643         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417   0.000734     0.0675   0.000517   0.000119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/99         0G    0.09739    0.07239     0.0321         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417   0.000734     0.0675    0.00054   0.000125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/99         0G    0.09054     0.0757    0.02673         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417   0.000636     0.0585   0.000541   0.000135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/99         0G    0.08529    0.07218    0.02309         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417   0.000658     0.0605    0.00137   0.000242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/99         0G    0.08153    0.06577    0.01909         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.709     0.0347     0.0201     0.0072\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/99         0G    0.07546    0.06065    0.01733         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.771       0.13     0.0851     0.0288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/99         0G    0.07214    0.06129     0.0171         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.794      0.162      0.121     0.0433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/99         0G    0.06545    0.05282    0.01696         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.791      0.203      0.116     0.0474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/99         0G    0.06288     0.0517    0.01545         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.799      0.184      0.128     0.0496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/99         0G     0.0578    0.04985    0.01477         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.879      0.225      0.236        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/99         0G    0.05691    0.04648    0.01454         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.903      0.221      0.268     0.0919\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/99         0G    0.05553    0.04464    0.01308         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.608      0.333      0.305      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/99         0G    0.05525    0.04582    0.01198         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.772      0.379      0.414      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/99         0G    0.05328    0.04836    0.01109         61        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.694      0.399      0.395      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/99         0G    0.05121    0.04325    0.01094         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.776      0.409      0.424       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/99         0G    0.04915    0.04405    0.00958         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417       0.81      0.404      0.439      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/99         0G      0.048    0.04332   0.009782         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.813        0.4      0.472      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/99         0G    0.04799    0.04267   0.009437         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.798      0.401      0.474      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/99         0G    0.04488    0.03795    0.00825         23        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.831      0.417      0.464      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/99         0G    0.04606    0.03986   0.009173         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.859      0.456      0.519      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/99         0G    0.04444    0.03896    0.00889         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.866      0.459      0.544      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/99         0G    0.04455    0.04035   0.007764         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        417      0.865      0.448      0.486      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/99         0G    0.04238    0.04027    0.00857        326        640:  ^C\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "!python train.py --img 640 --batch 32 --epochs 100 --data data/data.yaml --cfg models/custom_yolov5s.yaml --weights yolov5s.pt --name yolov5s_results --cache"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección en tiempo real usando detect.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/Users/facundobarafani/Documents/UCC/sistemas_inteligentes/tp_final/detect.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source 0 --img 640 --data data/data.yaml --weights ./runs/train/yolov5s_results2/weights/best.pt --conf 0.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
